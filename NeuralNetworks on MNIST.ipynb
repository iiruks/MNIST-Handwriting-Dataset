{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba85fae1",
   "metadata": {},
   "source": [
    "\n",
    "# Step 1 Data Acquisition and Visualization: In this step, you need to:\n",
    "(a) Download the “MNIST” dataset and extract the files. You will get four files with\n",
    "extension .gz (e.g., train-images-idx3-ubyte.gz). You can use the provided function read_idx\n",
    "below to read in the dataset. As its official description, the dataset is split into 60000 training\n",
    "images and 10000 images. The four file corresponds to the training images, training labels,\n",
    "testing images and testing labels. You need to print out their shape to finish this step. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96efb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28)\n",
      "Train labels shape: (60000,)\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import requests\n",
    "import struct\n",
    "\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for _ in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "file_names = ['train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz', \n",
    "              't10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "for file_name in file_names:\n",
    "    r = requests.get(url + file_name)\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "train_images = read_idx(file_names[0])\n",
    "train_labels = read_idx(file_names[1])\n",
    "test_images = read_idx(file_names[2])\n",
    "test_labels = read_idx(file_names[3])\n",
    "\n",
    "print(\"Train images shape:\", train_images.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape) \n",
    "print(\"Test images shape:\", test_images.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383448d",
   "metadata": {},
   "source": [
    "(b) To further understand what the dataset is, you need to use the ‘matplotlib’ library to\n",
    "print out a random data with code plt.imshow together with its label.(5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a3e8490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a random index\n",
    "idx = np.random.randint(0, len(train_images))\n",
    "\n",
    "# Print out the label\n",
    "print(\"Label: \", train_labels[idx]) \n",
    "\n",
    "# Reshape the 784 pixel vector to a 28x28 image\n",
    "img = train_images[idx].reshape(28,28)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Label: {}\".format(train_labels[idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d1f258",
   "metadata": {},
   "source": [
    "# Step 2 Data Preprocessing: In this step, you need to:\n",
    "(a) Normalize the pixel values of images to be between 0 and 1. (5 pts)\n",
    "(b) Convert the labels from categorical data into numerical values using one-hot encoding.\n",
    "(5 pts) hint: you can explore the eye function in Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1197c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized train images shape: (60000, 28, 28)\n",
      "One-hot encoded train labels shape: (60000, 10)\n",
      "Normalized test images shape: (10000, 28, 28)\n",
      "One-hot encoded test labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Normalize images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = 10\n",
    "train_labels_one_hot = np.eye(num_classes)[train_labels] \n",
    "test_labels_one_hot = np.eye(num_classes)[test_labels]\n",
    "\n",
    "print(\"Normalized train images shape:\", train_images.shape)\n",
    "print(\"One-hot encoded train labels shape:\", train_labels_one_hot.shape)\n",
    "\n",
    "print(\"Normalized test images shape:\", test_images.shape)  \n",
    "print(\"One-hot encoded test labels shape:\", test_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587a5a0",
   "metadata": {},
   "source": [
    "# Step 3 Network Initialization: We will work with a neuron network with two hidden layers, using Sigmoid function as the activation functions for hidden layers and softmax activation function for the output layer. To finish this, you need to:\n",
    "(a) Identify the auxiliary input including the Sigmoid function and its derivative and\n",
    "Softmax function (5 pts)\n",
    "(b) Initialize all the parameters in neural network uniformly. In this network, the input size\n",
    "is 784 dimensions (each input is a 28x28 image, so you have to flatten the data from 2D to 1D). For the two linear hidden layers, we have 128 and 64 neurons respectively. For\n",
    "the output layer, its size will be 10 since there are 10 classes (0-9) in MNIST. To finish\n",
    "this step, you need to initialize the weights and bias in random with a pre-set random\n",
    "seed using Numpy. Please set the seed value = 695. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23494d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def softmax_derivative(x):\n",
    "    s = softmax(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6bdc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(695) \n",
    "\n",
    "input_size = 784 # 28x28 images\n",
    "hidden_layer1_size = 128\n",
    "hidden_layer2_size = 64\n",
    "num_classes = 10\n",
    "\n",
    "# Initialize weights\n",
    "w1 = np.random.uniform(size=(input_size, hidden_layer1_size)) \n",
    "w2 = np.random.uniform(size=(hidden_layer1_size, hidden_layer2_size))\n",
    "w3 = np.random.uniform(size=(hidden_layer2_size, num_classes))\n",
    "\n",
    "# Initialize biases \n",
    "b1 = np.zeros(hidden_layer1_size)\n",
    "b2 = np.zeros(hidden_layer2_size)\n",
    "b3 = np.zeros(num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c8bcc",
   "metadata": {},
   "source": [
    "# Step 4 Feed Forward: In this step, you need to:\n",
    "(a) define a function named feed_forward. Given an input x, it should output the sigmoid of\n",
    "wx+b where w and b indicates the weights and bias defined in step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c588d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feed_forward(x, w1, b1, w2, b2, w3, b3):\n",
    "\n",
    "    # Hidden layer 1\n",
    "    z1 = x.dot(w1) + b1 \n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    z2 = a1.dot(w2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    # Output layer\n",
    "    z3 = a2.dot(w3) + b3\n",
    "    y = softmax(z3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542be8f",
   "metadata": {},
   "source": [
    "# Step 5 Back Propagation: In this step, you need to implement the back\n",
    "propagation:\n",
    "(a) You need to compute the loss for the output layer first. Here, we use categorical cross\n",
    "entropy loss function given below for multi-class classification problem. (5 pts) Note, to\n",
    "achieve this, you need to first encode the categorical labels as numerical values using\n",
    "one-hot encoding finished in step 2. (b) Calculate the gradients for the weights and bias for each layer. Use the chain rule to\n",
    "compute gradients for previous layers. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b8efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "\n",
    "    # One-hot encode y_true\n",
    "    y_true = np.eye(num_classes)[y_true]\n",
    "    \n",
    "    # Compute cross-entropy loss \n",
    "    loss = -np.sum(y_true * np.log(y_pred))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8b36a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Categorical cross-entropy loss\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "  loss = -np.sum(y_true * np.log(y_pred))\n",
    "  return loss\n",
    "\n",
    "# (b) Compute gradients\n",
    "def backprop(x, y_true, W1, b1, W2, b2, W3, b3):\n",
    "\n",
    "  # feedforward\n",
    "  y_pred = feed_forward(x, W1, b1, W2, b2, W3, b3)\n",
    "  \n",
    "  # gradients\n",
    "  dL_dy = y_pred - y_true # for output layer\n",
    "  \n",
    "  dL_dW3 = a2.T.dot(dL_dy) \n",
    "  dL_db3 = np.sum(dL_dy, axis=0)\n",
    "  \n",
    "  dL_da2 = dL_dy.dot(W3.T)\n",
    "  dL_dz2 = dL_da2 * sigmoid_deriv(z2)\n",
    "  \n",
    "  dL_dW2 = a1.T.dot(dL_dz2)\n",
    "  dL_db2 = np.sum(dL_dz2, axis=0)\n",
    "\n",
    "  dL_da1 = dL_dz2.dot(W2.T) \n",
    "  dL_dz1 = dL_da1 * sigmoid_deriv(z1)\n",
    "\n",
    "  dL_dW1 = x.T.dot(dL_dz1)\n",
    "  dL_db1 = np.sum(dL_dz1, axis=0)\n",
    "\n",
    "  return dL_dW1, dL_db1, dL_dW2, dL_db2, dL_dW3, dL_db3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989b1273",
   "metadata": {},
   "source": [
    "# Step 6 Model Training: In this step, you need to:\n",
    "(a) Use mini-batch gradient descent to update the parameters including weights and bias.\n",
    "Notice that a complete training round consists of a feed forward process, back\n",
    "propagation and parameter update. Define the batch size = 128 and epoch = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0750db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs with batch size 128\n",
    "for epoch in range(100):\n",
    "  X_train = []\n",
    "  for i in range(0, len(X_train), 128):\n",
    "    batch_X = X_train[i:i+128]\n",
    "    batch_y = y_train[i:i+128]\n",
    "\n",
    "    # Feedforward\n",
    "    y_pred = feed_forward(batch_X, W1, b1, W2, b2, W3, b3)\n",
    "    \n",
    "    # Backprop\n",
    "    dL_dW1, dL_db1, dL_dW2, dL_db2, dL_dW3, dL_db3 = backprop(batch_X, batch_y, W1, b1, W2, b2, W3, b3)\n",
    "    \n",
    "    # Update weights & biases\n",
    "    W1 -= learning_rate * dL_dW1\n",
    "    b1 -= learning_rate * dL_db1\n",
    "    W2 -= learning_rate * dL_dW2 \n",
    "    b2 -= learning_rate * dL_db2\n",
    "    W3 -= learning_rate * dL_dW3\n",
    "    b3 -= learning_rate * dL_db3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9e3bf",
   "metadata": {},
   "source": [
    "# Step 7 Model Evaluation: In this step, you need to:\n",
    "(a) Use your trained neural network to predict the labels of the test dataset and compute\n",
    "the accuracy on the test dataset. (5 pts)\n",
    "Remark: if you correctly execute every step above, you will probably get a result around\n",
    "90%.\n",
    "(b) Plot some of the misclassified images with their predicted and true labels. (5 pts) This\n",
    "probably can give you some insights into why these images are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e56fc4c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m W3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(hidden_dim2, output_dim) \n\u001b[1;32m     15\u001b[0m b3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(output_dim)\n\u001b[0;32m---> 17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m y_pred_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m y_true_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m, in \u001b[0;36mfeed_forward\u001b[0;34m(x, w1, b1, w2, b2, w3, b3)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward\u001b[39m(x, w1, b1, w2, b2, w3, b3):\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Hidden layer 1\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     z1 \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m(w1) \u001b[38;5;241m+\u001b[39m b1 \n\u001b[1;32m      7\u001b[0m     a1 \u001b[38;5;241m=\u001b[39m sigmoid(z1)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Hidden layer 2\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dot'"
     ]
    }
   ],
   "source": [
    "input_dim = 784\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "output_dim = 695\n",
    "\n",
    "# Step 3 - Initialize network parameters\n",
    "\n",
    "W1 = np.random.randn(input_dim, hidden_dim1)\n",
    "b1 = np.random.randn(hidden_dim1) \n",
    "\n",
    "W2 = np.random.randn(hidden_dim1, hidden_dim2)\n",
    "b2 = np.random.randn(hidden_dim2)\n",
    "\n",
    "W3 = np.random.randn(hidden_dim2, output_dim) \n",
    "b3 = np.random.randn(output_dim)\n",
    "\n",
    "y_pred = feed_forward(X_test, W1, b1, W2, b2, W3, b3)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(y_pred_labels == y_true_labels)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "# (b) Plot misclassified examples\n",
    "misclassified_idx = np.where(y_pred_labels != y_true_labels)[0]\n",
    "num_plots = 25 \n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(10,10))\n",
    "for i, idx in enumerate(misclassified_idx[:num_plots]):\n",
    "    img = X_test[idx].reshape(28,28)\n",
    "    ax = axs[i//5, i%5] \n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"True: {y_true_labels[idx]}\\nPred: {y_pred_labels[idx]}\")\n",
    "    ax.axis('off') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638150c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
