{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PART 1:"
      ],
      "metadata": {
        "id": "THdBHBEYomxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are the advantages of a CNN over a fully connected deep neural network for image classification?"
      ],
      "metadata": {
        "id": "VVEQFkecpW8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some key advantages of using a CNN over a fully connected network for image classification include:\n",
        "Parameter efficiency - By leveraging convolution layers, CNNs can extract features from images using far fewer parameters compared to fully connected layers. This makes them more efficient.\n",
        "Translational invariance - CNNs can detect features regardless of their location in the image, thanks to pooling layers. This makes them well-suited for image tasks.\n",
        "Ability to preserve spatial information - Convolutional layers preserve the spatial relationship between pixels, which is important for image tasks. Fully connected networks lose this spatial information."
      ],
      "metadata": {
        "id": "O2d8-t10pVFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?"
      ],
      "metadata": {
        "id": "GR7XmC0Vpgn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a max pooling layer instead of a convolutional layer with the same stride reduces computational complexity. Max pooling layers simply downsample the input, reducing dimensions and parameters in the network. Convolutional layers have to learn filters to apply to the input, which is more complex."
      ],
      "metadata": {
        "id": "Kr4aXJcLplNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. When would you want to add a local response normalization layer?"
      ],
      "metadata": {
        "id": "aPy1iAWHpl3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Local response normalization layers can be useful when dealing with high frequency features in images. They help normalize activations and improve generalization by enforcing lateral inhibition between activated neurons. This can be helpful in early convolutional layers."
      ],
      "metadata": {
        "id": "BuU9950Mpl6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Test below CNN codes with MNIST data set and show the model accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "T-021Fb3pl8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WfCvu2DcPhD",
        "outputId": "94954c11-b322-4957-ef1a-e917a8e1baa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "8LWnJ2pDgExZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu-29xg8iYoY",
        "outputId": "68456173-1c6c-4606-8785-e2240a35748a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV5LT_huickz",
        "outputId": "3fd3737c-1091-4c65-8992-16cd67bc7ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "2qGcLQkPgSmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.utils.np_utils import to_categorical"
      ],
      "metadata": {
        "id": "drGDKZuQgkPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RlHwCtU4bKrh",
        "outputId": "47bbb8e1-bada-4012-846b-f9cac47bc2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train original shape (60000, 28, 28)\n",
            "y_train original shape (60000,)\n",
            "X_test original shape (10000, 28, 28)\n",
            "y_test original shape (10000,)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 12, 12, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 10, 10, 64)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 4, 4, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 594922 (2.27 MB)\n",
            "Trainable params: 594922 (2.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-0b814fd985a2>:162: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "937/937 [==============================] - 148s 156ms/step - loss: 0.2047 - accuracy: 0.9347 - val_loss: 0.0336 - val_accuracy: 0.9894\n",
            "Epoch 2/5\n",
            "937/937 [==============================] - 143s 153ms/step - loss: 0.0649 - accuracy: 0.9802 - val_loss: 0.0228 - val_accuracy: 0.9927\n",
            "Epoch 3/5\n",
            "937/937 [==============================] - 147s 157ms/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 0.0188 - val_accuracy: 0.9938\n",
            "Epoch 4/5\n",
            "937/937 [==============================] - 143s 153ms/step - loss: 0.0407 - accuracy: 0.9876 - val_loss: 0.0183 - val_accuracy: 0.9938\n",
            "Epoch 5/5\n",
            "937/937 [==============================] - 149s 159ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.0196 - val_accuracy: 0.9932\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.0196 - accuracy: 0.9932\n",
            "\n",
            "Test accuracy:  0.9932000041007996\n",
            "313/313 [==============================] - 6s 17ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhfElEQVR4nO3deXRU9f3/8VdYMmzJxBizyZaAgoKEipCyCFgjEJcCgsXtFK1VsUFRFD3Yr6K2GguuKCr2eKBWcaGt4NJiFUw4yqKASCk2JRgLSBIUm5kQTMDk8/uDn1NH1jtMeGd5Ps75nJO59/Oe+57rNS/u3MmdGOecEwAAx1kL6wYAAM0TAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBHjUtWtXXXXVVdZtAI0eAQT8f1u2bNH111+vzMxMtWnTRvHx8Ro8eLAef/xxffPNN9btHVZBQYFiYmIOOlatWmXdHnBQrawbABqCt956S5dccol8Pp9+/vOfq3fv3tq7d6/ef/99TZs2Tf/85z/17LPPWrd5RDfddJP69+8ftqx79+5G3QCHRwCh2SspKdGll16qLl26aNmyZUpLSwuty8vLU3Fxsd566y3DDo/e2WefrfHjx1u3ARwV3oJDszdz5kzt3r1bzz33XFj4fKd79+6aMmXKIeu//vpr3XbbbTrjjDPUoUMHxcfHKzc3V5988skBc5944gn16tVL7dq10wknnKCzzjpLCxYsCK2vrKzUzTffrK5du8rn8yk5OVnnnXee1q1bd9Svp7KyUt9+++1RzwescAaEZu+NN95QZmamBg0aFFH9Z599pkWLFumSSy5RRkaGysvLNXfuXA0bNkybNm1Senq6JOn3v/+9brrpJo0fP15TpkxRdXW1NmzYoNWrV+vyyy+XJE2aNEl/+tOfNHnyZJ1++unatWuX3n//fX366ac688wzj9jL1Vdfrd27d6tly5Y6++yzNWvWLJ111lkRvS6gvsXwfUBozoLBoPx+v0aPHq1FixYdVU3Xrl01fPhwzZ8/X5JUU1Oj1q1bq0WL/72h8Pnnn6tnz5769a9/rbvuukuSNGbMGBUXF2vjxo2HfO6EhARdeeWVevLJJz29jhUrVuiRRx7R+eefr6SkJG3atEkPPfSQqqqqtGLFCv3oRz/y9HzA8cAZEJq1YDAoSYqLi4v4OXw+X+jn2tpaVVRUqEOHDurRo0fYW2cJCQnavn27PvroowM+KPD9OatXr9aOHTtCZ05HY9CgQWFncD/96U81fvx49enTR9OnT9eSJUsieGVA/eIaEJq1+Ph4Sfuvm0Sqrq5Ojz76qE455RT5fD4lJSXppJNO0oYNGxQIBELz7rjjDnXo0EEDBgzQKaecory8PH3wwQdhzzVz5kxt3LhRnTp10oABA3TPPffos88+i6iv7t27a/To0XrvvfdUW1sb8esD6gsBhGYtPj5e6enph31b7EgeeOABTZ06VUOHDtULL7ygt99+W++884569eqlurq60LzTTjtNRUVFevnllzVkyBD9+c9/1pAhQzRjxozQnJ/97Gf67LPP9MQTTyg9PV2zZs1Sr1699Le//S2i3jp16qS9e/eqqqoq4tcH1BeuAaHZu/766/Xss89qxYoVGjhw4BHn//AaUN++fZWYmKhly5aFzevYsaO6d++ugoKCgz7P3r17dfHFF2vJkiXavXu32rRpc8CcnTt36swzz1TXrl31/vvve35t48eP11tvvaWqqqqwa1RAQ8ARiWbv9ttvV/v27fXLX/5S5eXlB6zfsmWLHn/88UPWt2zZUj/8d9zChQv1xRdfhC3btWtX2OPY2Fidfvrpcs5p3759qq2tDXvLTpKSk5OVnp6umpqaw76GL7/88oBln3zyiV5//XWNGDGC8EGDxIcQ0Ox169ZNCxYs0IQJE3TaaaeF3QlhxYoVWrhw4WHv/XbhhRfqvvvu09VXX61BgwbpH//4h1588UVlZmaGzRsxYoRSU1M1ePBgpaSk6NNPP9WTTz6pCy64QHFxcaqoqFDHjh01fvx4ZWVlqUOHDnr33Xf10Ucf6eGHHz7sa5gwYYLatm2rQYMGKTk5WZs2bdKzzz6rdu3a6cEHH4zGbgKizwFwzjn373//21177bWua9euLjY21sXFxbnBgwe7J554wlVXV4fmdenSxU2cODH0uLq62t16660uLS3NtW3b1g0ePNitXLnSDRs2zA0bNiw0b+7cuW7o0KHuxBNPdD6fz3Xr1s1NmzbNBQIB55xzNTU1btq0aS4rK8vFxcW59u3bu6ysLPfUU08dsffHH3/cDRgwwCUmJrpWrVq5tLQ0d+WVV7rNmzdHbf8A0cY1IACACd4YBgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmGtwfotbV1WnHjh2Ki4tTTEyMdTsAAI+cc6qsrFR6evph78LR4AJox44d6tSpk3UbAIBjtG3bNnXs2PGQ6xvcW3DH8r0sAICG40i/z+stgObMmaOuXbuqTZs2ys7O1ocffnhUdbztBgBNw5F+n9dLAL3yyiuaOnWqZsyYoXXr1ikrK0sjR47Uzp0762NzAIDGqD5uMDdgwACXl5cXelxbW+vS09Ndfn7+EWsDgYCTxGAwGIxGPr670e6hRP0MaO/evVq7dq1ycnJCy1q0aKGcnBytXLnygPk1NTUKBoNhAwDQ9EU9gL766ivV1tYqJSUlbHlKSorKysoOmJ+fny+/3x8afAIOAJoH80/BTZ8+XYFAIDS2bdtm3RIA4DiI+t8BJSUlqWXLlgd8tXF5eblSU1MPmO/z+eTz+aLdBgCggYv6GVBsbKz69eunpUuXhpbV1dVp6dKlGjhwYLQ3BwBopOrlTghTp07VxIkTddZZZ2nAgAF67LHHVFVVpauvvro+NgcAaITqJYAmTJigL7/8UnfffbfKysrUt29fLVmy5IAPJgAAmq8Y55yzbuL7gsGg/H6/dRsAgGMUCAQUHx9/yPXmn4IDADRPBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEy0sm4AaEhatmzpucbv99dDJ9ExefLkiOratWvnuaZHjx6ea/Ly8jzXPPTQQ55rLrvsMs81klRdXe255sEHH/Rcc++993quaQo4AwIAmCCAAAAmoh5A99xzj2JiYsJGz549o70ZAEAjVy/XgHr16qV33333fxtpxaUmAEC4ekmGVq1aKTU1tT6eGgDQRNTLNaDNmzcrPT1dmZmZuuKKK7R169ZDzq2pqVEwGAwbAICmL+oBlJ2drfnz52vJkiV6+umnVVJSorPPPluVlZUHnZ+fny+/3x8anTp1inZLAIAGKOoBlJubq0suuUR9+vTRyJEj9de//lUVFRV69dVXDzp/+vTpCgQCobFt27ZotwQAaIDq/dMBCQkJOvXUU1VcXHzQ9T6fTz6fr77bAAA0MPX+d0C7d+/Wli1blJaWVt+bAgA0IlEPoNtuu02FhYX6/PPPtWLFCo0dO1YtW7aM+FYYAICmKepvwW3fvl2XXXaZdu3apZNOOklDhgzRqlWrdNJJJ0V7UwCARizqAfTyyy9H+ynRQHXu3NlzTWxsrOeaQYMGea4ZMmSI5xpp/zVLr8aNGxfRtpqa7du3e66ZPXu255qxY8d6rjnUp3CP5JNPPvFcU1hYGNG2miPuBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEjHPOWTfxfcFgUH6/37qNZqVv374R1S1btsxzDf9tG4e6ujrPNb/4xS881+zevdtzTSRKS0sjqvvvf//ruaaoqCiibTVFgUBA8fHxh1zPGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwEQr6wZgb+vWrRHV7dq1y3MNd8Peb/Xq1Z5rKioqPNecc845nmskae/evZ5r/vjHP0a0LTRfnAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwc1Ioa+//jqiumnTpnmuufDCCz3XfPzxx55rZs+e7bkmUuvXr/dcc95553muqaqq8lzTq1cvzzWSNGXKlIjqAC84AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGAixjnnrJv4vmAwKL/fb90G6kl8fLznmsrKSs81c+fO9VwjSddcc43nmiuvvNJzzUsvveS5BmhsAoHAYf+f5wwIAGCCAAIAmPAcQMuXL9dFF12k9PR0xcTEaNGiRWHrnXO6++67lZaWprZt2yonJ0ebN2+OVr8AgCbCcwBVVVUpKytLc+bMOej6mTNnavbs2XrmmWe0evVqtW/fXiNHjlR1dfUxNwsAaDo8fyNqbm6ucnNzD7rOOafHHntM//d//6fRo0dLkp5//nmlpKRo0aJFuvTSS4+tWwBAkxHVa0AlJSUqKytTTk5OaJnf71d2drZWrlx50JqamhoFg8GwAQBo+qIaQGVlZZKklJSUsOUpKSmhdT+Un58vv98fGp06dYpmSwCABsr8U3DTp09XIBAIjW3btlm3BAA4DqIaQKmpqZKk8vLysOXl5eWhdT/k8/kUHx8fNgAATV9UAygjI0OpqalaunRpaFkwGNTq1as1cODAaG4KANDIef4U3O7du1VcXBx6XFJSovXr1ysxMVGdO3fWzTffrN/+9rc65ZRTlJGRobvuukvp6ekaM2ZMNPsGADRyngNozZo1Ouecc0KPp06dKkmaOHGi5s+fr9tvv11VVVW67rrrVFFRoSFDhmjJkiVq06ZN9LoGADR63IwUTdKsWbMiqvvuH1ReFBYWeq75/p8qHK26ujrPNYAlbkYKAGiQCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmuBs2mqT27dtHVPfGG294rhk2bJjnmtzcXM81f//73z3XAJa4GzYAoEEigAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggpuRAt/TrVs3zzXr1q3zXFNRUeG55r333vNcs2bNGs81kjRnzhzPNQ3sVwkaAG5GCgBokAggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJjgZqTAMRo7dqznmnnz5nmuiYuL81wTqTvvvNNzzfPPP++5prS01HMNGg9uRgoAaJAIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY4GakgIHevXt7rnnkkUc815x77rmeayI1d+5czzX333+/55ovvvjCcw1scDNSAECDRAABAEx4DqDly5froosuUnp6umJiYrRo0aKw9VdddZViYmLCxqhRo6LVLwCgifAcQFVVVcrKytKcOXMOOWfUqFEqLS0NjZdeeumYmgQAND2tvBbk5uYqNzf3sHN8Pp9SU1MjbgoA0PTVyzWggoICJScnq0ePHrrhhhu0a9euQ86tqalRMBgMGwCApi/qATRq1Cg9//zzWrp0qX73u9+psLBQubm5qq2tPej8/Px8+f3+0OjUqVO0WwIANECe34I7kksvvTT08xlnnKE+ffqoW7duKigoOOjfJEyfPl1Tp04NPQ4Gg4QQADQD9f4x7MzMTCUlJam4uPig630+n+Lj48MGAKDpq/cA2r59u3bt2qW0tLT63hQAoBHx/Bbc7t27w85mSkpKtH79eiUmJioxMVH33nuvxo0bp9TUVG3ZskW33367unfvrpEjR0a1cQBA4+Y5gNasWaNzzjkn9Pi76zcTJ07U008/rQ0bNugPf/iDKioqlJ6erhEjRug3v/mNfD5f9LoGADR63IwUaCQSEhI811x00UURbWvevHmea2JiYjzXLFu2zHPNeeed57kGNrgZKQCgQSKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmOBu2AAOUFNT47mmVSvP3+6ib7/91nNNJN8tVlBQ4LkGx467YQMAGiQCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmvN89EMAx69Onj+ea8ePHe67p37+/5xopshuLRmLTpk2ea5YvX14PncACZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMcDNS4Ht69OjhuWby5Mmeay6++GLPNampqZ5rjqfa2lrPNaWlpZ5r6urqPNegYeIMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAluRooGL5KbcF522WURbSuSG4t27do1om01ZGvWrPFcc//993uuef311z3XoOngDAgAYIIAAgCY8BRA+fn56t+/v+Li4pScnKwxY8aoqKgobE51dbXy8vJ04oknqkOHDho3bpzKy8uj2jQAoPHzFECFhYXKy8vTqlWr9M4772jfvn0aMWKEqqqqQnNuueUWvfHGG1q4cKEKCwu1Y8eOiL58CwDQtHn6EMKSJUvCHs+fP1/Jyclau3athg4dqkAgoOeee04LFizQT37yE0nSvHnzdNppp2nVqlX68Y9/HL3OAQCN2jFdAwoEApKkxMRESdLatWu1b98+5eTkhOb07NlTnTt31sqVKw/6HDU1NQoGg2EDAND0RRxAdXV1uvnmmzV48GD17t1bklRWVqbY2FglJCSEzU1JSVFZWdlBnyc/P19+vz80OnXqFGlLAIBGJOIAysvL08aNG/Xyyy8fUwPTp09XIBAIjW3bth3T8wEAGoeI/hB18uTJevPNN7V8+XJ17NgxtDw1NVV79+5VRUVF2FlQeXn5If+Y0OfzyefzRdIGAKAR83QG5JzT5MmT9dprr2nZsmXKyMgIW9+vXz+1bt1aS5cuDS0rKirS1q1bNXDgwOh0DABoEjydAeXl5WnBggVavHix4uLiQtd1/H6/2rZtK7/fr2uuuUZTp05VYmKi4uPjdeONN2rgwIF8Ag4AEMZTAD399NOSpOHDh4ctnzdvnq666ipJ0qOPPqoWLVpo3Lhxqqmp0ciRI/XUU09FpVkAQNMR45xz1k18XzAYlN/vt24DRyElJcVzzemnn+655sknn/Rc07NnT881Dd3q1as918yaNSuibS1evNhzTV1dXUTbQtMVCAQUHx9/yPXcCw4AYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCKib0RFw5WYmOi5Zu7cuRFtq2/fvp5rMjMzI9pWQ7ZixQrPNQ8//LDnmrfffttzzTfffOO5BjheOAMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggpuRHifZ2dmea6ZNm+a5ZsCAAZ5rTj75ZM81Dd2ePXsiqps9e7bnmgceeMBzTVVVlecaoKnhDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJbkZ6nIwdO/a41BxPmzZt8lzz5ptveq759ttvPdc8/PDDnmskqaKiIqI6AN5xBgQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEjHPOWTfxfcFgUH6/37oNAMAxCgQCio+PP+R6zoAAACYIIACACU8BlJ+fr/79+ysuLk7JyckaM2aMioqKwuYMHz5cMTExYWPSpElRbRoA0Ph5CqDCwkLl5eVp1apVeuedd7Rv3z6NGDFCVVVVYfOuvfZalZaWhsbMmTOj2jQAoPHz9I2oS5YsCXs8f/58JScna+3atRo6dGhoebt27ZSamhqdDgEATdIxXQMKBAKSpMTExLDlL774opKSktS7d29Nnz5de/bsOeRz1NTUKBgMhg0AQDPgIlRbW+suuOACN3jw4LDlc+fOdUuWLHEbNmxwL7zwgjv55JPd2LFjD/k8M2bMcJIYDAaD0cRGIBA4bI5EHECTJk1yXbp0cdu2bTvsvKVLlzpJrri4+KDrq6urXSAQCI1t27aZ7zQGg8FgHPs4UgB5ugb0ncmTJ+vNN9/U8uXL1bFjx8POzc7OliQVFxerW7duB6z3+Xzy+XyRtAEAaMQ8BZBzTjfeeKNee+01FRQUKCMj44g169evlySlpaVF1CAAoGnyFEB5eXlasGCBFi9erLi4OJWVlUmS/H6/2rZtqy1btmjBggU6//zzdeKJJ2rDhg265ZZbNHToUPXp06deXgAAoJHyct1Hh3ifb968ec4557Zu3eqGDh3qEhMTnc/nc927d3fTpk074vuA3xcIBMzft2QwGAzGsY8j/e7nZqQAgHrBzUgBAA0SAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEgwsg55x1CwCAKDjS7/MGF0CVlZXWLQAAouBIv89jXAM75airq9OOHTsUFxenmJiYsHXBYFCdOnXStm3bFB8fb9ShPfbDfuyH/dgP+7Ef9msI+8E5p8rKSqWnp6tFi0Of57Q6jj0dlRYtWqhjx46HnRMfH9+sD7DvsB/2Yz/sx37Yj/2wn/V+8Pv9R5zT4N6CAwA0DwQQAMBEowogn8+nGTNmyOfzWbdiiv2wH/thP/bDfuyH/RrTfmhwH0IAADQPjeoMCADQdBBAAAATBBAAwAQBBAAwQQABAEw0mgCaM2eOunbtqjZt2ig7O1sffvihdUvH3T333KOYmJiw0bNnT+u26t3y5ct10UUXKT09XTExMVq0aFHYeuec7r77bqWlpalt27bKycnR5s2bbZqtR0faD1ddddUBx8eoUaNsmq0n+fn56t+/v+Li4pScnKwxY8aoqKgobE51dbXy8vJ04oknqkOHDho3bpzKy8uNOq4fR7Mfhg8ffsDxMGnSJKOOD65RBNArr7yiqVOnasaMGVq3bp2ysrI0cuRI7dy507q1465Xr14qLS0Njffff9+6pXpXVVWlrKwszZkz56DrZ86cqdmzZ+uZZ57R6tWr1b59e40cOVLV1dXHudP6daT9IEmjRo0KOz5eeuml49hh/SssLFReXp5WrVqld955R/v27dOIESNUVVUVmnPLLbfojTfe0MKFC1VYWKgdO3bo4osvNuw6+o5mP0jStddeG3Y8zJw506jjQ3CNwIABA1xeXl7ocW1trUtPT3f5+fmGXR1/M2bMcFlZWdZtmJLkXnvttdDjuro6l5qa6mbNmhVaVlFR4Xw+n3vppZcMOjw+frgfnHNu4sSJbvTo0Sb9WNm5c6eT5AoLC51z+//bt27d2i1cuDA059NPP3WS3MqVK63arHc/3A/OOTds2DA3ZcoUu6aOQoM/A9q7d6/Wrl2rnJyc0LIWLVooJydHK1euNOzMxubNm5Wenq7MzExdccUV2rp1q3VLpkpKSlRWVhZ2fPj9fmVnZzfL46OgoEDJycnq0aOHbrjhBu3atcu6pXoVCAQkSYmJiZKktWvXat++fWHHQ8+ePdW5c+cmfTz8cD9858UXX1RSUpJ69+6t6dOna8+ePRbtHVKDuxv2D3311Veqra1VSkpK2PKUlBT961//MurKRnZ2tubPn68ePXqotLRU9957r84++2xt3LhRcXFx1u2ZKCsrk6SDHh/frWsuRo0apYsvvlgZGRnasmWL7rzzTuXm5mrlypVq2bKldXtRV1dXp5tvvlmDBw9W7969Je0/HmJjY5WQkBA2tykfDwfbD5J0+eWXq0uXLkpPT9eGDRt0xx13qKioSH/5y18Muw3X4AMI/5Obmxv6uU+fPsrOzlaXLl306quv6pprrjHsDA3BpZdeGvr5jDPOUJ8+fdStWzcVFBTo3HPPNeysfuTl5Wnjxo3N4jro4RxqP1x33XWhn8844wylpaXp3HPP1ZYtW9StW7fj3eZBNfi34JKSktSyZcsDPsVSXl6u1NRUo64ahoSEBJ166qkqLi62bsXMd8cAx8eBMjMzlZSU1CSPj8mTJ+vNN9/Ue++9F/b9Yampqdq7d68qKirC5jfV4+FQ++FgsrOzJalBHQ8NPoBiY2PVr18/LV26NLSsrq5OS5cu1cCBAw07s7d7925t2bJFaWlp1q2YycjIUGpqatjxEQwGtXr16mZ/fGzfvl27du1qUseHc06TJ0/Wa6+9pmXLlikjIyNsfb9+/dS6deuw46GoqEhbt25tUsfDkfbDwaxfv16SGtbxYP0piKPx8ssvO5/P5+bPn+82bdrkrrvuOpeQkODKysqsWzuubr31VldQUOBKSkrcBx984HJyclxSUpLbuXOndWv1qrKy0n388cfu448/dpLcI4884j7++GP3n//8xznn3IMPPugSEhLc4sWL3YYNG9zo0aNdRkaG++abb4w7j67D7YfKykp32223uZUrV7qSkhL37rvvujPPPNOdcsoprrq62rr1qLnhhhuc3+93BQUFrrS0NDT27NkTmjNp0iTXuXNnt2zZMrdmzRo3cOBAN3DgQMOuo+9I+6G4uNjdd999bs2aNa6kpMQtXrzYZWZmuqFDhxp3Hq5RBJBzzj3xxBOuc+fOLjY21g0YMMCtWrXKuqXjbsKECS4tLc3Fxsa6k08+2U2YMMEVFxdbt1Xv3nvvPSfpgDFx4kTn3P6PYt91110uJSXF+Xw+d+6557qioiLbpuvB4fbDnj173IgRI9xJJ53kWrdu7bp06eKuvfbaJvePtIO9fklu3rx5oTnffPON+9WvfuVOOOEE165dOzd27FhXWlpq13Q9ONJ+2Lp1qxs6dKhLTEx0Pp/Pde/e3U2bNs0FAgHbxn+A7wMCAJho8NeAAABNEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBM/D/erMpcaQ8+cwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "get_ipython().magic(u'matplotlib inline')\n",
        "\n",
        "\n",
        "# In[2]:\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM\n",
        "\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#from keras.utils import np_utils\n",
        "from keras import utils\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "#from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "np.random.seed(25)\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(\"X_train original shape\", X_train.shape)\n",
        "print(\"y_train original shape\", y_train.shape)\n",
        "print(\"X_test original shape\", X_test.shape)\n",
        "print(\"y_test original shape\", y_test.shape)\n",
        "\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "\n",
        "plt.imshow(X_train[0], cmap='gray')\n",
        "plt.title('Class '+ str(y_train[0]))\n",
        "\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train/=255\n",
        "X_test/=255\n",
        "\n",
        "X_train.shape\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "\n",
        "number_of_classes = 10\n",
        "\n",
        "Y_train = utils.to_categorical(y_train, number_of_classes)\n",
        "Y_test = utils.to_categorical(y_test, number_of_classes)\n",
        "\n",
        "y_train[0], Y_train[0]\n",
        "\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "\n",
        "# Three steps to Convolution\n",
        "# 1. Convolution\n",
        "# 2. Activation\n",
        "# 3. Pooling\n",
        "# Repeat Steps 1,2,3 for adding more hidden layers\n",
        "\n",
        "# 4. After that make a fully connected network\n",
        "# This fully connected network gives ability to the CNN\n",
        "# to classify the samples\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
        "model.add(Activation('relu'))\n",
        "BatchNormalization(axis=-1)\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "BatchNormalization(axis=-1)\n",
        "model.add(Conv2D(64,(3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "BatchNormalization(axis=-1)\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "# Fully connected layer\n",
        "\n",
        "BatchNormalization()\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "BatchNormalization()\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10))\n",
        "\n",
        "# model.add(Convolution2D(10,3,3, border_mode='same'))\n",
        "# model.add(GlobalAveragePooling2D())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# In[10]:\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# In[11]:\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# In[12]:\n",
        "\n",
        "\n",
        "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
        " height_shift_range=0.08, zoom_range=0.08)\n",
        "\n",
        "test_gen = ImageDataGenerator()\n",
        "\n",
        "\n",
        "# In[13]:\n",
        "\n",
        "\n",
        "train_generator = gen.flow(X_train, Y_train, batch_size=64)\n",
        "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "# model.fit(X_train, Y_train, batch_size=128, nb_epoch=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5,\n",
        " validation_data=test_generator, validation_steps=10000//64)\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "print()\n",
        "print('Test accuracy: ', score[1])\n",
        "\n",
        "\n",
        "# In[ ]:\n",
        "\n",
        "\n",
        "#predictions = model.predict_classes(X_test)\n",
        "predictions = model.predict(X_test)\n",
        "classes_x=np.argmax(predictions,axis=1)\n",
        "\n",
        "predictions = list(predictions)\n",
        "actuals = list(y_test)\n",
        "\n",
        "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n",
        "sub.to_csv('./output_cnn.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Make comments on your results in 4."
      ],
      "metadata": {
        "id": "nEzIiyyip9ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CNN model achieves very good performance on the MNIST dataset. This simple CNN architecture of just 2 convolution + max pooling layers is able to efficiently extract features from the input images to classify the handwritten digits with high accuracy. Additional improvements could be made by tuning hyperparameters like number of filters, filter sizes, adding dropout, or more layers."
      ],
      "metadata": {
        "id": "Apciiu2fp8LP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2:"
      ],
      "metadata": {
        "id": "abJbb_pboszv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Use the below code to load the data set."
      ],
      "metadata": {
        "id": "eD28GoQsqZp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(\"Train samples:\", x_train.shape, y_train.shape)\n",
        "print(\"Test samples:\", x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itF-lU4hfmAI",
        "outputId": "fefe23ad-548e-48bf-b0aa-8a493009f96d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Train samples: (50000, 32, 32, 3) (50000, 1)\n",
            "Test samples: (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Show the 10 classes"
      ],
      "metadata": {
        "id": "u0MOY-wlqftt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",  \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# show random images from train\n",
        "cols = 8\n",
        "rows = 2\n",
        "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
        "for i in range(cols):\n",
        "  for j in range(rows):\n",
        "    random_index = np.random.randint(0, len(y_train))\n",
        "ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
        "ax.grid('off')\n",
        "ax.axis('off')\n",
        "ax.imshow(x_train[random_index, :])\n",
        "ax.set_title(cifar10_classes[y_train[random_index, 0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "LD-GobojqY5j",
        "outputId": "e8c47eda-c587-4ebc-d81c-cc051ebe7f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI8AAACmCAYAAADjwNxtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARg0lEQVR4nO2dS2wcVRaGz61XP9y22/EjScdOTAhRJDITzSAFzQoQQonEMogVUrIkIUgsQEgsMEJiY5QVUViCWDOIDUqEsh4JIcHARISEiR3ydGLH7Xe/qurOYgb3PX+lu2sujm2S861yXOV65bjuX+eec67SWmsSBAucjb4A4Y+LOI9gjTiPYI04j2CNOI9gjTiPYI04j2CNOI9gjTiPYI04DxE9++yztH///o77Xb16lZRS9Omnnz74i/oDIM4jWONt9AX8kdi1axdVKhXyfX+jL2VTIM7zf6CUomw2u9GXsWl4JIatxcVFeuONN2h0dJQymQwNDQ3RCy+8QN999x3b76effqLnnnuO8vk87dixg8bHx9n2+2meY8eOUaFQoImJCTp06BB1dXVRqVSi999/nx72hIVHwnleffVV+vjjj+nIkSN05swZevPNNymXy9HFixdX9ymXy3T48GE6cOAAnTp1ivbt20dvv/02nT17tuPxoyiiw4cP09atW2l8fJyeeuopGhsbo7GxsQd5WxuPfgTo7e3Vr732WsvtzzzzjCYi/dlnn63+rFar6W3btukjR46s/mxyclITkf7kk09Wf3b06FFNRPr1119f/Vkcx/rFF1/UQRDo6enptb2ZTcQj8eYpFov0zTff0K1bt1ruUygU6JVXXlm1gyCggwcP0sTERKpznDx5cvXfSik6efIk1et1On/+vP2Fb3IeCecZHx+nCxcu0MjICB08eJDee++9hFMMDw+TUor9rK+vj8rlcsfjO45Du3fvZj/bu3cvEf1XJz2sPBLO8/LLL9PExAR99NFHVCqV6MMPP6Qnn3yS6RnXde/7u/ohF72/h0fCeYiItm/fTidOnKAvv/ySJicnqb+/nz744IM1OXYcx4k32eXLl4mIaHR0dE3OsRl56J0niiKan59nPxsaGqJSqUS1Wm3NznP69OnVf2ut6fTp0+T7Pj3//PNrdo7NxkMfJFxcXKTh4WF66aWX6MCBA1QoFOj8+fP07bff0qlTp9bkHNlsls6dO0dHjx6lp59+ms6ePUtfffUVvfPOOzQ4OLgm59iMPPTOk8/n6cSJE/T111/TF198QXEc0549e+jMmTN0/PjxNTmH67p07tw5On78OL311lvU3d1NY2Nj9O67767J8TcrSosi/F0cO3aMPv/8c1paWtroS1l3HnrNIzw4xHkEa8R5BGtE8wjWyJtHsEacR7BGnEewJnWQ8O/f/8BsnIF2He6H5kSj4/FtjqPa2h7kCC8tLjJ7dnaW2U/seozZ2UwzVVTHMduGAg/vQ8G1NOKI2VdgDivfXWD2lqGB1X87it+3p/njxmsJNb/WiLgdgzxVMTzXNhk2eK444vcVgn1o93DLY62er+MegtACcR7BGnEewZrUmiehcSB5yvO8lttdFzVP+3P5LhzLcdvaBNfWbpvT4T4UXFxlmadt3Llzh9lbQBMNbdvaPBcc29XcxghbrBXYfLtCzQN/+4run9B2v9/F8B5uT4O8eQRrxHkEa8R5BGtSa54Y4iUOaIO2U2TJwR22J07GzTBk9grEfVaWV/i1UVM74HWixsH70hDvmLlzl9mTV64wu6+vj9nKuJc45MdCZaYJNQ7fPwY9hXEeB3+f7Y8ah587gvtEOw3y5hGsEecRrBHnEayxjvOglmhnK8I5Gd1yXyIi3+GXNT87x+wb124wu7R1O7Pzudzqv1sV8/0Gah7UJfUqj/MszPEynrDe4MdrNPWZgnNDGIc0ir0OUjAxDwdXa26P4/ZxnbVI45I3j2CNOI9gTephq9Nrr50d6/ZDA6Yu4BQCfmcuQAUofmaaUyWYksGtJB5cS0+Bp1xEMEzNztxj9q0bzSE119XFtg0ObuPHSlxb++eEA03imRtDFW5LhCQS/1+dnkwSefMI1ojzCNaI8wjWWGueTmOouR0/ljFlFTUNpkgGkJa6MD/H7Gql0vJaEqkH+GkO+iqK+VQIaib8PJ6EtNSBwWYaan//ANvW6ZkhjZDrK9w7cFtPEenEFFB7jYpTH2mQN49gjTiPYI04j2CNdUpGJ9sEw/QxpJFimL4OY70HpTu5HO/CfuPmTWb3DzS1BnZsT6SdguYpz80x+8cLF5g9M8vjOjsfG2X2yPBI89xBhm2rLPFUEh/uI4JYS3l6mtnFnl5m6zy/F7NUx8P/jkSKK2ighKLqjLx5BGvEeQRrxHkEa9Zsbgvnl5gGSsxVQUorjLe1ap3Z9ZDb5TLXHVo/zmxT59Tr/HexRAiv+/bUFLO7i1xnPPG/5ty/MTQ0xGwzJoXxqhXQPHmXP5f5Fd6aTsFzykFJUj3i92amtaoOmieZGSxzW8I6Is4jWCPOI1jzwOa2zHgKzrOEDT5/RFBiQhGP89y+zXUI6pYuyJupN5q/j9eJGge7wKOGwXPdvctLcTBOZGosMx2WiGhhfoHZy3DuhuLPaWiAz43h7JaKsBSnSWJqC58DSBws+0mDvHkEa8R5BGvEeQRr0s9tYZwHSoBxzsi0Q9gXc3ch3EEZjx9r584RZs/B/BLqkoaRZ4ztXfBaqtUqswuYswwaCTVOEATMNjVUIg8JyqSXpnm7ltG9e5jtwTON6vxanEQpT/MHGuI6YWIuEn4XdWcK5M0jWCPOI1gjziNYk1rzNGCOCOMnOYhpNIxYSwRBB5zqckAbYMwok+F5MVienLy21q1GMK6DGgbPbd7H/fbH52DGeSqgp1aWl5kd5Ph9od5CfcafEpEXt87RqePco+6keSSfR1hHxHkEa8R5BGtSa55lGK8xtoLjs7nd93ksxPXanzaRH90uV4iIVlZ4W7mKUceF8Se8TsxxRnB/1EC43Tx3HfQVxowGt2xpu11B3XwZWs3cu36L2aXhZst/v7eHXye2qAO9RKHEeYR1RJxHsCb1sDUF6Zn4uVwsFlva+PkbQmlNhB3iMUUS8gfwo3IFyo0rleYnsgdTHb6PH7xwLhgSazX+uY1prfgc+PAOaSo4XGNYANq3YMkSSoe7Uzw9pK/YHAZVgaep4LClYdjSmKORAnnzCNaI8wjWiPMI1qTWPD6Uzs5CWgSmH3Tn86v/jj34BPX5aat1risIdUmM7UAg3QBKdRaN1IcArru3lx87THyi8nNVazwM0AhxegO0goqMbdDlNQD9BWmnHpTSxCHfP8jyKaAn/rSfbzemiOqQ6htjR3hJQxU2EnEewRpxHsGa1Jqn0MtD6Tj+LkGrtysTzdVh+gb4yjA9W4rMjiFWEkN5sdtuJT8iqla4Zpq+02xNUiqV2DYH/l40lK+Q274UWsc8FrO8zMtp8obWwxQLR3O9lXP5sX3QfrPzPK4Tu/yZdxX5c42Mx4RTHYlYG65606ZFTivkzSNYI84jWCPOI1iTWvNUIDDgZXgqQ88gL42dnWnOu3z/wz/Ztl0jJbB3MtvxIC0V2tdqmBvDdm0DxrwalvHUV7iOwLTSRpXfJx57Bub4+iH1IWfEqKqLXA/dm7rN7PI1rkO68vyZ/nqTn8svcN2558BfmW1GdrA9Hqa1RDDX1cAS8L8dpE7Im0ewRpxHsEacR7AmteZZgjISLBEOPP6DipGemc1CS9kFvuTRz//6kdnbBqFVG7RTu3uTr/TXqEFLlutN3fLrvy+zbZg+i2XUvs//nubm+Rze5UuXmB1BLpF5fIx9zdy6xuyl8gw/FrSWqUT8me7Ys4/ZDZgDrBr6bWGB660EmEsE6bRpkDePYI04j2CNOI9gTWrNc/PaJLOzAR9vPQdbnDV1R1jlOTETk9eZjUse/ePeLLO7u/gcUQ3msjQM1zVjRWKc0xkYHGQ2zgENDfF41SLEaqau8WufvMQ1lZmHHDV47k8xw2NOWdBXuEykk+N5yFshllYqwbKTRnwM7xuX3sS5LIz7pEHePII14jyCNeI8gjWpNU9tjsck3AzXPD1FPsfTqDfH+yxBOzSIZ8zCnM+dW9yegpQbXL56cZ633TcXlca4zvwMr3XC7VPXrzI7UfoM8S4F5cexcd8Ky4dhns3zoW0c5DUpiG+NPs7bzvXBvFotNPOnOywXIJpH2EjEeQRrxHkEa1Jrnl8v/MBsHya3Fgf7mR01jPZqyzwnJoCxPw8xI8y5qVegVgrzcaHFrGssQxlhfKPKY0oBtKxDLYDaAUFdY94JdmoLQ1gOE647dPi5u7fkud3H83kaNazzaga8cAnvxHIPmJstS2ML64k4j2BN+umJX35h9koFykL28RXwfKOk+NLPF9m2LKSwdkEnVXyDRhGff9AwVOBfAFvhRcHKyprvjS1TEIUrzcAw1q5cWcN0QwPKdhS0NanV+X32Qkc1Ba1oag24dnOcxCGzQymOrG4srCviPII14jyCNelLb5bg8xmmGJbgc9o3xlQ3y1MLXJ9/HruggXq38NQDLIStLPE0CfxcZqu/wO824HMZNRGuJIN/XR60hwEJxfSa5oemyIXyF5iOcBwesliu8FSWO3d599NMD5+e0AQnNOi0MqN0gBfWFXEewRpxHsGa1JpnePcos12YUsC2KTljxeFtO4bZNhdSKnB147lZnv6xVOUpF8sVbrtQ9mN2fVcuxkq47YPe8t3214ZaIVGubKShhqALPWip4kFZtVJYZs33n50rM3srxKhcr6klO61G3UkDpUHePII14jyCNeI8gjWpNc++v/yZ2diatRtiDn6mqS0imP8xS2OIiCrLXMPEi7z0phfSPVwoYVExrmTTnCvLF3rZtnw3v858gdtYUoTXNj/PS6VRtzSM+aYqpH8QtMrNQ5tf1+U2wXYH9FiidZzRZKWT5um0PQ3y5hGsEecRrBHnEaxJrXk8aHmGK+hhrom5Ah6ubhxCq/oQZq+ysNxPadcIsxfKfDumuZr6qwjzZNl8N7O7UANBO5gV0DxqimucIOBxI3N5pwqUWYd1bvfkeBl14PNn7ATcRn2Fyzl5fuuU2U4aB/VTGuTNI1gjziNYI84jWJNa82gcTjEfBPJxHTOnBnKQMckmA/EM6uKaJobYC+bvBB7/G+g2ynCL0GLfz/JyFgdas3mgYXKa74+lOqh5HGPezs/C8kya52pnXb496/HtfobbuMxkov2tMkpvsOQIW+l2sNMgbx7BGnEewRpxHsGa1JqHQNNEGjUO2EZ+LtYnYaat50DrERjrCcZ6jbVWUA9VyDc1UwY0STYLsRQP8nsgfqXh2vCvTaF+M1rPeHCnSyHk1MDRPGhbg0tjY4I1tr9VTmvN0ymfRzSPsK6I8wjWiPMI1qTWPGabOCIiB8ufFM51Ne1E2xIYux0UDgiM3w7UO3lwbt+In+ChY9BfCnaIoQVeolY9YfPjBYY+03CfEeQw47VlC3zeDeu4sLSq0cDlNJvnTmgenNuSOI+wkYjzCNakHrZC6GaemPxPrCZjDCUaP9X5bysoxXHg9a4h3cOB6QhMVTCHrQykOfjwaa6w/AWLm13sYAp3rniYwDE6ppmlMETJsukGDhUw/IY4JwQHiBqwWp9upmhgykwiJQOGby3dUIX1RJxHsEacR7AmtebB8pZEl1Acn81WIzGmDqBuwPG5/ae9C51YHfh8NjcrSHlNjO0hTHXAuXB/BZ/yIXwuR8bxHIU9VuBaoHt8BKs24582hihwVZ26MV3hQsfZxKc7TjeJ5hHWE3EewRpxHsGa1JonaN2xjIiSKRlmLEdDHB7CNOQm5zrA5HYNjhfAXQRGnAi3OQ4f22PQV9gnzgHNFIDealQxPcTQHXCdGWgF40EaaoDtXXAJaTiehlSUWBmr3kTt/8MSaahSbiysJ+I8gjXiPII16cuNFY6JmFbBt5peidmUqBuwy1xi/QCI4/iokTzUFobmgfa1Dl5MYnmB9vGPDFxrBALO3J7F+4SU2BDLlfAZg40pGZhmwfSaAm2HLVai9mmpaZA3j2CNOI9gjTiPYI3SNj1UBYHkzSP8DsR5BGvEeQRrxHkEa8R5BGvEeQRrxHkEa8R5BGvEeQRr/gN1ydMI//Y2UgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define a CNN architecture and train your own model by playing with the network setup: like, performs convolution, performs 2D max pooling, changing activation function from ReLU to LeakyReLU, adding dropout etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "UJUQI75rqois"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary building blocks\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
        "model.add(Activation(LeakyReLU(alpha=0.1)))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation(LeakyReLU(alpha=0.1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation(LeakyReLU(alpha=0.1)))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation(LeakyReLU(alpha=0.1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(LeakyReLU(alpha=0.1)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(NUM_CLASSES))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# Train model\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WVjIoyJrjv7",
        "outputId": "d8c1e1c1-e328-4c62-fd38-9eb080689c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 218s 277ms/step - loss: 1.9098 - accuracy: 0.3912 - val_loss: 1.3012 - val_accuracy: 0.5435\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 207s 264ms/step - loss: 1.2721 - accuracy: 0.5508 - val_loss: 1.0329 - val_accuracy: 0.6403\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 206s 264ms/step - loss: 1.0901 - accuracy: 0.6169 - val_loss: 1.0374 - val_accuracy: 0.6436\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 211s 269ms/step - loss: 1.0042 - accuracy: 0.6499 - val_loss: 0.9260 - val_accuracy: 0.6781\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 208s 267ms/step - loss: 0.9364 - accuracy: 0.6731 - val_loss: 0.8508 - val_accuracy: 0.7108\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 209s 267ms/step - loss: 0.8882 - accuracy: 0.6923 - val_loss: 0.7882 - val_accuracy: 0.7228\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 207s 264ms/step - loss: 0.8502 - accuracy: 0.7028 - val_loss: 0.8798 - val_accuracy: 0.7096\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 208s 266ms/step - loss: 0.8324 - accuracy: 0.7110 - val_loss: 0.7371 - val_accuracy: 0.7455\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 206s 264ms/step - loss: 0.8120 - accuracy: 0.7189 - val_loss: 0.8033 - val_accuracy: 0.7182\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 208s 266ms/step - loss: 0.7920 - accuracy: 0.7258 - val_loss: 0.7687 - val_accuracy: 0.7376\n",
            "313/313 [==============================] - 12s 37ms/step - loss: 0.7687 - accuracy: 0.7376\n",
            "Test accuracy: 0.7376000285148621\n"
          ]
        }
      ]
    }
  ]
}